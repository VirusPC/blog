---
title: "学习算法评估"
categories: ['机器学习']
tags: []
resource_path: /blog/assets/2019/03/23/evaluating
---

<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>

学习算法评估
===

---

提升系统性能
---

* 提升系统性能的一些方法：
  * 获取更多的训练样本 —— 有时并没有什么用
  * 选用更少的特征集 —— 避免过拟合
  * 获取额外的特征 —— 避免过拟合
  * 添加多项式特征 —— $$x_1^2, x_2^2, x_1x_2$$ 等等
  * 调整lambda值  
* 大多数人是凭感觉随便从这些方法中选择一种，这会浪费大量的时间。我们可以通过“机器学习诊断法”（Machine learning diagnostic）来避免这一问题。
* “诊断法”是一种测试，你可以通过运行它来了解一个学习算法是否有效，以获取如何提升性能的指引。实现它需要花费一些时间，但是这样做可以更好的利用你的时间。它可以让你在开发学习算法时早点从不必要的尝试中解脱出来。
* 在此之前，我们需要先学习如何评估机器学习算法的性能。

留出法(hold-out)
---

* 一个假设函数可能会过拟合。为了评估一个假设函数，我们可以把给定的数据集随机的分为两部分：训练集和测试集。通常训练集占70%，测试集占30%。此方法也被称为留出法（hold-out）。
* 此外，最好保持两个集合数据分布的一致性（分层采样），例如在分类问题中，至少要保持样本的类别比例相似。
* 使用这两个集合的训练过程：
  1. 学习$$\Theta$$，并且使用训练集来最小化$$J_{train}(\Theta)$$
  2. 计算测试集的误差$$J_{test}(\Theta)$$
* 测试集误差
  * 线性回归：  
    $$ J_{test}(\Theta) = \frac{1}{2m_{test}} \sum_{i=1}^{m_{test}} (h_\Theta(x^{(i)}_{test}) - y_{test}^{(i)} )^2$$
  * 逻辑回归——误分类率（Misclassification error），也被称为0/1误分率（0/1 misclassification error）：
    $$ err(h_\Theta(x),y)=
    \begin{cases}
    1 \quad 若\ h_\Theta(x) \ge 0.5\ 且 y=0\ 或\ h_\Theta(x) < 0.5\ 且\ y=1\\
    0 \quad 其它
    \end{cases}\\
    测试误差= \frac{1}{m_{test}} \sum_{i=1}^{m_{test}} err(h_\Theta(x_{test}^{(i)}),y_{test}^{(i)}) $$
* 使用留出法时，一般要采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果。例如进行100次划分，每次产生一个训练/测试集用于实验评估，100次后就得到100个结果，而留出法返回的则是这100个结果的平均。

交叉验证法(cross validation)
---

* 基本思路：
  * 交叉验证法先将数据集D划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性。
  * 然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，从而可以进行k次训练和测试。
  * 最终返回这k个测试结果的均值。
* 交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为了强调这一点，通常把交叉验证法称为“k折交叉验证”（k-fold cross validation）。k最常用的取值是10，此时称为10折交叉验证。其它常用的k值有5、20等。
* 与留出法类似，将数据集划分为k个子集，有很多种划分方式。为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分方式重复p次再次取均值。常见的有“10次10折交叉验证”。

留一法(Leave-One-Out, LOO)
---

* 假定数据集D中包含m个样本，若令k=m，则得到了交叉验证法的特例：留一法。
* 显然，此方法只有一种划分D的方式，故无需再重复p次。
  
自助法(bootstrapping)
---

* 我们希望评估用的是用D训练出的模型，但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比D小，这必然会引入一些因训练样本规模不同而导致的估计偏差。留一法受样本规模变化的影响较小，但计算复杂度又太高。
* 自助发可以减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计。
* 自助法以自助采样法（bootstrap sampling）为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D'：每次随即从D中挑选一个样本，将其副本拷入D'中，重复m次。我们采用D'用作训练集，D-D'用作测试集。
* 样本在m次采样中始终不被采到的概率是：  
  $$(1-\frac{1}{m})^m$$  
  取极限得到：  
  $$ \lim_{m \rightarrow \infty}(1-\frac{1}{m})^m = \frac{1}{e} \approx 0.368 $$  
  即通过自助采样，初始数据集D中约有36.8%的样本未出现在D'中，取这D-D'部分为测试集，D为'为训练集合占约63.2%。
* 优点:  
  自助法在数据集较小、难以划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。
* 缺点：  
  自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。
* 在初始数据量足够时，留出法和交叉验证法更常用。

模型选择
---

* 对于某组数据，最合适的多项式次数是几次，怎样选用正确的特征来构造学习算法，或者如何选择正则化参数lambda 此类的问题称之为模型选择问题。
* 对于给定的的不同多项式阶的模型，我们可以通过系统的方法来确定最佳的函数。为了选择你的假设的模型，你可以测试多项式的每个阶数并且观察误差结果。
* 首先将数据集分为三部分，他们的比例通常为：
  * 训练集：60%
  * 交叉验证集（cross validation set）：20%
  * 测试集：20%
* 然后使用下面的方法计算三个集合各自的误差值：
  1. 使用训练集为每个维度的多项式最优化参数，即分别得出各个维度多项式对应的模型。  
     （注意在优化过程中的损失函数是包含正则化项的,得到最优化参数后计算$$J_{train}(\theta)$$时是不含正则化项的）
  2. 使用交叉验证集计算损失，找到误差最小的多项式维度。即从上一步的所有模型中选出最好的一个。
  3. 使用测试集合对上一步找到的多项式计算损失，估计泛化误差。用以评估模型最终的泛化性能。
* 通过这种方式，把多项式的维度d这一特征提取了出来，避免了将其用于测试集

---

课程链接：

* [Evaluating a Hypothesis](https://www.coursera.org/learn/machine-learning/supplement/aFpD3/evaluating-a-hypothesis)
* [Model Selection and Train/Validation/TestSet]()

---

其他参考资料：

* [1]周志华.机器学习[M].北京:清华大学出版社,2016：23-28.